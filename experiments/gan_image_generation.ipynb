{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90dbb4e",
   "metadata": {},
   "source": [
    "# Image generation using GAN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca053e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d647f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available and set the device accordingly\n",
    "if torch.accelerator.is_available():\n",
    "    device = torch.accelerator.current_accelerator().type\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444ebd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model parameters from saved checkpoint\n",
    "def load_model(model, checkpoint_path):\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print(\"Checkpoint loaded successfully\")\n",
    "    else:\n",
    "        print(f\"No checkpoint found at {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087ee46",
   "metadata": {},
   "source": [
    "## Image generated by a simple GAN model\n",
    "\n",
    "A simple GAN generator model trained on MNIST dataset takes a random noise vector of size 100 and generates an 28x28 grayscale fake image of a digit. The generated digit resembles to any of the actual training digits between 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eedaf90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, g_input_dim, g_output_dim):\n",
    "        super(Generator, self).__init__()       \n",
    "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x): \n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        return torch.tanh(self.fc4(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f656f573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ../saved_models/gan_mnist_pytorch/gan_mnist_pytorch_G_epoch_200.pth\n",
      "Checkpoint loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Define model and optimizer\n",
    "g_input_dim = 100  # Example input dimension\n",
    "g_output_dim = 784  # Example output dimension (e.g., for MNIST)\n",
    "generator = Generator(g_input_dim, g_output_dim)\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "# Load model from checkpoint\n",
    "checkpoint_path = '../saved_models/gan_mnist_pytorch/gan_mnist_pytorch_G_epoch_200.pth'\n",
    "load_model(generator, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d7fb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a random noise vector z\n",
    "g_input_dim = 100  # Example input dimension\n",
    "z = torch.randn(1, g_input_dim)\n",
    "# Generate an image using the generator\n",
    "generated_image = generator(z)\n",
    "\n",
    "# Reshape the generated image to 28x28 for visualization\n",
    "generated_image = generated_image.view(generated_image.size(0), 1, 28, 28)\n",
    "# Display the generated image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(generated_image[0, 0].detach().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c9995",
   "metadata": {},
   "source": [
    "## Image generation by Conditional-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61c0795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a conditional generator model\n",
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, noise_dim, label_dim):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim + label_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate noise and labels\n",
    "        input = torch.cat((noise, labels), dim=1)\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af02625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ../saved_models/conditional_gan_mnist_pytorch/conditional_gan_generator_epoch_60.pth\n",
      "Checkpoint loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "noise_dim = 100\n",
    "label_dim = 10  # MNIST has 10 classes (0-9)\n",
    "conditionalGenerator = ConditionalGenerator(noise_dim, label_dim)\n",
    "optimizer = torch.optim.Adam(conditionalGenerator.parameters(), lr=0.0002)\n",
    "\n",
    "# Load model from checkpoint\n",
    "checkpoint_path = '../saved_models/conditional_gan_mnist_pytorch/conditional_gan_generator_epoch_60.pth'\n",
    "load_model(conditionalGenerator, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12839f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate an image using the generator for label 5\n",
    "label = torch.tensor([9], device=device)\n",
    "noise = torch.randn(1, noise_dim, device=device)\n",
    "label_one_hot = F.one_hot(label, num_classes=label_dim).float().to(device)\n",
    "\n",
    "# Move the model to the correct device\n",
    "conditionalGenerator = conditionalGenerator.to(device)\n",
    "\n",
    "generated_image = conditionalGenerator(noise, label_one_hot)\n",
    "# Reshape the generated image to 28x28 for visualization\n",
    "generated_image = generated_image.view(generated_image.size(0), 1, 28, 28)\n",
    "# Display the generated image\n",
    "plt.imshow(generated_image[0, 0].detach().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
